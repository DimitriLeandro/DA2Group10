{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimitriLeandro/DA2Group10/blob/main/final_project_part_i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a020db",
      "metadata": {
        "id": "43a020db"
      },
      "source": [
        "# Data Analytics II - Final Project Part I"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e0d92f7",
      "metadata": {
        "id": "2e0d92f7"
      },
      "source": [
        "## Methodology:\n",
        "\n",
        "- Feature scaling\n",
        "\n",
        "- Feature importance using Gini Index\n",
        "\n",
        "- Deletion of unnecessary features\n",
        "\n",
        "- Correlation between features\n",
        "\n",
        "For each classifier:\n",
        "\n",
        "    - SFS analysis using standard hyperparameters\n",
        "    \n",
        "    - Gridsearch using the selected features\n",
        "\n",
        "    - Analysis of classification metrics\n",
        "\n",
        "- Fitting of the best model with all the training data\n",
        "\n",
        "- Predictions to the test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd7cc4f",
      "metadata": {
        "id": "5fd7cc4f"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9388edd0",
      "metadata": {
        "id": "9388edd0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import json\n",
        "import xgboost as xgb\n",
        "from time import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.feature_selection import SequentialFeatureSelector \n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wuZo0unlIo5N",
      "metadata": {
        "id": "wuZo0unlIo5N"
      },
      "source": [
        "## Downloading and unziping datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aZoa22InInfy",
      "metadata": {
        "id": "aZoa22InInfy"
      },
      "outputs": [],
      "source": [
        "!wget https://uni-muenster.sciebo.de/s/bmzyEnwSscZ0tam/download?path=%2F&files=train_set.csv\n",
        "!unzip -qq /content/download?path=%2F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BBvRsrAZK9Ej",
      "metadata": {
        "id": "BBvRsrAZK9Ej"
      },
      "source": [
        "## Mounting drive to save results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tnNrpj30LDID",
      "metadata": {
        "id": "tnNrpj30LDID"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8faec9d",
      "metadata": {
        "id": "c8faec9d"
      },
      "source": [
        "## Training dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5af4a30",
      "metadata": {
        "id": "b5af4a30"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/task_1/train_set.csv') # /home/dimi/Downloads/task_1_datasets/train_set.csv\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df.drop('y', axis=1))\n",
        "\n",
        "y  = df['y']\n",
        "X  = pd.DataFrame(\n",
        "    data    = scaler.transform(df.drop('y', axis=1)),\n",
        "    columns = df.columns.drop('y')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79134040",
      "metadata": {
        "id": "79134040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "caea6cee-5e63-446e-b021-2dfd1b6ec0f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          label count        pct\n",
              "0                         teddy  7409  23.361922\n",
              "1              golden_retriever  5315   16.75916\n",
              "2            Labrador_retriever  3540  11.162263\n",
              "3                    toy_poodle  2885   9.096929\n",
              "4                      Cardigan  2869   9.046478\n",
              "5                 Border_collie  2554   8.053226\n",
              "6           miniature_schnauzer  2302   7.258624\n",
              "7                Siberian_husky  1120   3.531563\n",
              "8                French_bulldog  1081   3.408589\n",
              "9                           pug   758   2.390112\n",
              "10              standard_poodle   276   0.870278\n",
              "11            Italian_greyhound   198    0.62433\n",
              "12                   Weimaraner   195    0.61487\n",
              "13          Rhodesian_ridgeback   190   0.599104\n",
              "14     Chesapeake_Bay_retriever   175   0.551807\n",
              "15  German_short_haired_pointer   171   0.539194\n",
              "16              German_shepherd   171   0.539194\n",
              "17          African_hunting_dog   171   0.539194\n",
              "18                     Doberman   169   0.532888\n",
              "19              Tibetan_mastiff   165   0.520275"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49e65d1b-359f-4cc0-9ce8-38296bae3e6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>count</th>\n",
              "      <th>pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>teddy</td>\n",
              "      <td>7409</td>\n",
              "      <td>23.361922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>golden_retriever</td>\n",
              "      <td>5315</td>\n",
              "      <td>16.75916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Labrador_retriever</td>\n",
              "      <td>3540</td>\n",
              "      <td>11.162263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>toy_poodle</td>\n",
              "      <td>2885</td>\n",
              "      <td>9.096929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cardigan</td>\n",
              "      <td>2869</td>\n",
              "      <td>9.046478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Border_collie</td>\n",
              "      <td>2554</td>\n",
              "      <td>8.053226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>miniature_schnauzer</td>\n",
              "      <td>2302</td>\n",
              "      <td>7.258624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Siberian_husky</td>\n",
              "      <td>1120</td>\n",
              "      <td>3.531563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>French_bulldog</td>\n",
              "      <td>1081</td>\n",
              "      <td>3.408589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pug</td>\n",
              "      <td>758</td>\n",
              "      <td>2.390112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>standard_poodle</td>\n",
              "      <td>276</td>\n",
              "      <td>0.870278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Italian_greyhound</td>\n",
              "      <td>198</td>\n",
              "      <td>0.62433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Weimaraner</td>\n",
              "      <td>195</td>\n",
              "      <td>0.61487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rhodesian_ridgeback</td>\n",
              "      <td>190</td>\n",
              "      <td>0.599104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Chesapeake_Bay_retriever</td>\n",
              "      <td>175</td>\n",
              "      <td>0.551807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>German_short_haired_pointer</td>\n",
              "      <td>171</td>\n",
              "      <td>0.539194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>German_shepherd</td>\n",
              "      <td>171</td>\n",
              "      <td>0.539194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>African_hunting_dog</td>\n",
              "      <td>171</td>\n",
              "      <td>0.539194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Doberman</td>\n",
              "      <td>169</td>\n",
              "      <td>0.532888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Tibetan_mastiff</td>\n",
              "      <td>165</td>\n",
              "      <td>0.520275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49e65d1b-359f-4cc0-9ce8-38296bae3e6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49e65d1b-359f-4cc0-9ce8-38296bae3e6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49e65d1b-359f-4cc0-9ce8-38296bae3e6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_label_counts = pd.DataFrame(\n",
        "    data    = np.transpose(np.unique(y, return_counts=True)),\n",
        "    columns = ['label', 'count'] \n",
        ").sort_values(\n",
        "    by        = 'count',\n",
        "    ascending = False\n",
        ").reset_index(\n",
        "    drop = True\n",
        ")\n",
        "\n",
        "df_label_counts['pct'] = 100*df_label_counts['count']/y.size\n",
        "\n",
        "df_label_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7e1440",
      "metadata": {
        "id": "7a7e1440"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf86fed",
      "metadata": {
        "id": "faf86fed"
      },
      "outputs": [],
      "source": [
        "# rf = RandomForestClassifier(\n",
        "#     n_estimators = 1000,\n",
        "#     n_jobs       = -1,\n",
        "#     max_samples  = 0.66\n",
        "# )\n",
        "# rf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XGhB-oYwPNtE",
      "metadata": {
        "id": "XGhB-oYwPNtE"
      },
      "outputs": [],
      "source": [
        "# df_feature_importances = pd.DataFrame(\n",
        "#     data    = zip(df.columns.drop('y'), rf.feature_importances_),\n",
        "#     columns = ['feature', 'importance'] \n",
        "# ).sort_values(\n",
        "#     by        = 'importance',\n",
        "#     ascending = False,\n",
        "# ).reset_index(\n",
        "#     drop = True\n",
        "# )\n",
        "\n",
        "# df_feature_importances.to_csv(\n",
        "#     'results/task_1/feature_importance_final_project_part_i.csv', #'/content/drive/MyDrive/Colab Notebooks/feature_importance_final_project_part_i.csv', \n",
        "#     index = False\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6f239f",
      "metadata": {
        "id": "be6f239f"
      },
      "outputs": [],
      "source": [
        "max_features = 30\n",
        "df_feature_importances = pd.read_csv('results/task_1/feature_importance_final_project_part_i.csv')\n",
        "fig = px.bar(\n",
        "    data_frame = df_feature_importances[:max_features],\n",
        "    x          = 'feature',\n",
        "    y          = 'importance'\n",
        ")\n",
        "fig.update_xaxes(tickangle=90)\n",
        "fig.write_image('results/task_1/feature_importance_final_project_part_i.pdf')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4952b2a",
      "metadata": {
        "id": "e4952b2a"
      },
      "source": [
        "## Correlation between features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b209ee",
      "metadata": {
        "id": "16b209ee"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(18,14))\n",
        "sb.heatmap(X[df_feature_importances.loc[:8, 'feature']].corr(), cmap=\"Blues\", annot=True, linewidths=0.1)\n",
        "fig.savefig('results/task_1/feature_correlations_final_project_part_i.pdf')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2172cf3",
      "metadata": {
        "id": "e2172cf3"
      },
      "source": [
        "Features are not correlated: no need to remove correlated features to prevent overfitting!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3a8d56",
      "metadata": {
        "id": "ff3a8d56"
      },
      "source": [
        "## SFS to each classifier\n",
        "\n",
        "OBS: no need for SFS when using Random Forests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "777e32de",
      "metadata": {
        "id": "777e32de"
      },
      "outputs": [],
      "source": [
        "n_jobs               = -1\n",
        "cv                   = 10\n",
        "verbose              = 3\n",
        "n_features_to_select = 100\n",
        "plot_step            = 10\n",
        "scoring              = 'accuracy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad35cff",
      "metadata": {
        "id": "2ad35cff"
      },
      "outputs": [],
      "source": [
        "def run_sfs(estimator, X, y, n_features_to_select, cv, scoring, n_jobs, sorted_features=None, plot_step=1):\n",
        "    \n",
        "    if sorted_features is None:\n",
        "        sfs = SequentialFeatureSelector(\n",
        "            estimator            = estimator,\n",
        "            direction            = 'forward',\n",
        "            n_features_to_select = n_features_to_select,\n",
        "            n_jobs               = n_jobs,\n",
        "            cv                   = cv,\n",
        "            scoring              = scoring,\n",
        "        )\n",
        "        sfs.fit(X, y)\n",
        "        sorted_features = sfs.get_feature_names_out()\n",
        "    \n",
        "    kf               = KFold(n_splits=cv, shuffle=True)\n",
        "    accs             = []\n",
        "    stds             = []\n",
        "    n_features_range = np.arange(plot_step, n_features_to_select+1, plot_step)\n",
        "\n",
        "    for n_features in n_features_range:\n",
        "        print(n_features)\n",
        "        features   = sorted_features[:n_features]\n",
        "        inner_accs = []\n",
        "\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            X_train, X_test = X.loc[train_index][features], X.loc[test_index][features]\n",
        "            y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "            clf = estimator\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            inner_accs.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "        accs.append(np.mean(inner_accs))\n",
        "        stds.append(np.std(inner_accs))\n",
        "\n",
        "    fig = px.line(\n",
        "        x       = n_features_range,\n",
        "        y       = accs,\n",
        "        error_y = stds,\n",
        "        title   = 'Sequential Feature Selector: ' + estimator.__class__.__name__,\n",
        "        labels  = dict(\n",
        "            x = 'Number of features', \n",
        "            y = 'Accuracy'\n",
        "        )\n",
        "    )\n",
        "    fig.update_xaxes(tickvals=n_features_range)\n",
        "    fig.write_image('results/task_1/sfs_{}_final_project_part_i.pdf'.format(estimator.__class__.__name__))\n",
        "    fig.show()\n",
        "    \n",
        "    np.savetxt(\n",
        "        fname = 'results/task_1/sfs_{}_final_project_part_i.csv'.format(estimator.__class__.__name__), \n",
        "        X     = sorted_features, \n",
        "        fmt   = '%s'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed38e43",
      "metadata": {
        "id": "3ed38e43"
      },
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b059a38e",
      "metadata": {
        "id": "b059a38e"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "run_sfs(\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    X[df_feature_importances.loc[:100, 'feature']],\n",
        "    y,\n",
        "    n_features_to_select,\n",
        "    cv,\n",
        "    scoring,\n",
        "    n_jobs,\n",
        "    df_feature_importances['feature'],\n",
        "    plot_step\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47eed40c",
      "metadata": {
        "id": "47eed40c"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12a070ea",
      "metadata": {
        "id": "12a070ea"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "run_sfs(\n",
        "    KNeighborsClassifier(n_jobs=n_jobs),\n",
        "    X[df_feature_importances.loc[:100, 'feature']],\n",
        "    y,\n",
        "    n_features_to_select,\n",
        "    cv,\n",
        "    scoring,\n",
        "    n_jobs,\n",
        "    df_feature_importances['feature'],\n",
        "    plot_step\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47debd3c",
      "metadata": {
        "id": "47debd3c"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f16c9d",
      "metadata": {
        "id": "80f16c9d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "run_sfs(\n",
        "    SVC(),\n",
        "    X[df_feature_importances.loc[:100, 'feature']],\n",
        "    y,\n",
        "    n_features_to_select,\n",
        "    cv,\n",
        "    scoring,\n",
        "    n_jobs,\n",
        "    df_feature_importances['feature'],\n",
        "    plot_step\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2959597f",
      "metadata": {
        "id": "2959597f"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3561d5d4",
      "metadata": {
        "id": "3561d5d4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "run_sfs(\n",
        "    LogisticRegression(n_jobs=n_jobs),\n",
        "    X[df_feature_importances.loc[:100, 'feature']],\n",
        "    y,\n",
        "    n_features_to_select,\n",
        "    cv,\n",
        "    scoring,\n",
        "    n_jobs,\n",
        "    df_feature_importances['feature'],\n",
        "    plot_step\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1736bf",
      "metadata": {
        "id": "be1736bf"
      },
      "source": [
        "## Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a429979",
      "metadata": {
        "id": "3a429979"
      },
      "outputs": [],
      "source": [
        "def run_gridsearch(estimator, X, y, param_grid, cv, scoring, n_jobs, verbose):\n",
        "    gs = GridSearchCV(\n",
        "        estimator  = estimator,\n",
        "        n_jobs     = n_jobs,\n",
        "        cv         = cv,\n",
        "        verbose    = verbose,\n",
        "        scoring    = scoring,\n",
        "        param_grid = param_grid\n",
        "    )\n",
        "    gs.fit(X, y)\n",
        "    results = {\n",
        "        'Estimator': str(estimator.__class__.__name__),\n",
        "        'Number of features': X.shape[1],\n",
        "        'Best result': '{:.3f} +- {:.3f}'.format(\n",
        "            float(gs.cv_results_['mean_test_score'][gs.best_index_]),\n",
        "            float(gs.cv_results_['std_test_score'][gs.best_index_]),\n",
        "        ),\n",
        "        'Best hyperparameters': gs.best_params_\n",
        "    }\n",
        "    with open(\n",
        "        file = 'results/task_1/gridsearch_{}_final_project_part_i.json'.format(estimator.__class__.__name__),\n",
        "        mode = 'w'\n",
        "    ) as file:\n",
        "        json.dump(results, file, indent=4)\n",
        "    print(results)\n",
        "    return gs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf44471",
      "metadata": {
        "id": "ecf44471"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd30bd4",
      "metadata": {
        "id": "5cd30bd4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "param_grid = dict(\n",
        "    n_estimators      = [1000],\n",
        "    criterion         = ['gini'],\n",
        "    max_depth         = [10, 11, 12],\n",
        "    class_weight      = [None],\n",
        "    max_samples       = [0.66, 0.75, 1]\n",
        ")\n",
        "\n",
        "run_gridsearch(\n",
        "    RandomForestClassifier(), \n",
        "    X[df_feature_importances.loc[:100, 'feature']], \n",
        "    y, \n",
        "    param_grid, \n",
        "    cv, \n",
        "    scoring, \n",
        "    n_jobs, \n",
        "    verbose\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e4a6e8",
      "metadata": {
        "id": "c1e4a6e8"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92e4bc5",
      "metadata": {
        "id": "b92e4bc5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "param_grid = dict(\n",
        "    n_neighbors = [5, 10, 15, 20, 25, 30], #large K to prevent overfitting!\n",
        ")\n",
        "\n",
        "run_gridsearch(\n",
        "    KNeighborsClassifier(), \n",
        "    X[df_feature_importances.loc[:60, 'feature']], \n",
        "    y, \n",
        "    param_grid, \n",
        "    cv, \n",
        "    scoring, \n",
        "    1, # using just one kernel with KNN localy, otherwise, memory fuuuuuull \n",
        "    verbose\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09dde873",
      "metadata": {
        "id": "09dde873"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a492583",
      "metadata": {
        "id": "7a492583"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "param_grid = dict(\n",
        "    kernel                  = ['linear', 'poly', 'rbf'],\n",
        "    degree                  = [2, 3, 4, 5],\n",
        "    decision_function_shape = ['ovo', 'ovr']\n",
        ")\n",
        "\n",
        "run_gridsearch(\n",
        "    SVC(), \n",
        "    X[df_feature_importances.loc[:50, 'feature']], \n",
        "    y, \n",
        "    param_grid, \n",
        "    cv, \n",
        "    scoring, \n",
        "    n_jobs, \n",
        "    verbose\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a525b728",
      "metadata": {
        "id": "a525b728"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9234549e",
      "metadata": {
        "id": "9234549e"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "param_grid = dict(\n",
        "    solver   = ['saga'],\n",
        "    penalty  = ['elasticnet'],\n",
        "    C        = [0.5, 0.75, 1, 1.25, 1.5],\n",
        "    l1_ratio = [0.01, 0.25, 0.5, 0.75, 0.99]\n",
        ")\n",
        "\n",
        "run_gridsearch(\n",
        "    LogisticRegression(), \n",
        "    X[df_feature_importances.loc[:80, 'feature']], \n",
        "    y, \n",
        "    param_grid, \n",
        "    cv, \n",
        "    scoring, \n",
        "    n_jobs, \n",
        "    verbose\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1dc78c",
      "metadata": {
        "id": "5a1dc78c"
      },
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da2b89b",
      "metadata": {
        "id": "9da2b89b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "param_grid = dict()\n",
        "\n",
        "run_gridsearch(\n",
        "    LinearDiscriminantAnalysis(), \n",
        "    X[df_feature_importances.loc[:90, 'feature']], \n",
        "    y, \n",
        "    param_grid, \n",
        "    cv, \n",
        "    scoring, \n",
        "    n_jobs, \n",
        "    verbose\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG Boost"
      ],
      "metadata": {
        "id": "PVKC7d7FnXo7"
      },
      "id": "PVKC7d7FnXo7"
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding y\n",
        "encoder   = LabelEncoder()\n",
        "y_encoder = encoder.fit_transform(y)\n",
        "\n",
        "# random split to start with (true cross validation later)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoder, test_size=0.2, random_state=0)\n",
        "\n",
        "# xgb data matrices\n",
        "D_train = xgb.DMatrix(X_train, label=y_train)\n",
        "D_test  = xgb.DMatrix(X_test, label=y_test)"
      ],
      "metadata": {
        "id": "NPywmOvfnbDJ"
      },
      "id": "NPywmOvfnbDJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGB gridsearch (without sklearn API)\n",
        "\n",
        "The reason not to use sklearn API is to speed up the process by using GPU support"
      ],
      "metadata": {
        "id": "f-63fZ1dRkaq"
      },
      "id": "f-63fZ1dRkaq"
    },
    {
      "cell_type": "code",
      "source": [
        "initial_params = {\n",
        "    'num_parallel_tree': 10, # used for boosting random forest\n",
        "    'max_depth':         5,  # maximum tree depth for base learners\n",
        "    'eta':               0.25, # boosting learning rate \n",
        "    'subsample':         0.75, # subsample ratio of the training instance\n",
        "    'colsample_bytree':  0.75, # subsample ratio of columns when constructing each tree\n",
        "    'colsample_bylevel': 1, # subsample ratio of columns when constructing each tree\n",
        "    'colsample_bynode':  1, # subsample ratio of columns when constructing each tree\n",
        "    'gamma':             1,  # minimum loss reduction required to make a further partition on a leaf\n",
        "    'alpha':             0,  # L1 regularization term on weights \n",
        "    'lambda':            1,  # L2 regularization term on weights\n",
        "    'sampling_method':   'gradient_based', # select samples based in their errors (not uniform)\n",
        "    'tree_method':       'gpu_hist',     # make it fast\n",
        "    'predictor':         'gpu_predictor' # make it fast\n",
        "}\n",
        "\n",
        "grid_params = {\n",
        "    'max_depth':         [3, 5, 8, 10, 12, 15], # maximum tree depth for base learners\n",
        "    'gamma':             [0, 1, 5, 10],   # minimum loss reduction required to make a further partition on a leaf\n",
        "    'alpha':             [0, 0.5, 1, 1.5, 2], # L1 regularization term on weights \n",
        "    'lambda':            [0, 0.5, 1, 1.5, 2], # L2 regularization term on weights\n",
        "    'subsample':         [0.66, 0.75, 1], # subsample ratio of the training instance\n",
        "    'colsample_bytree':  [0.66, 0.75, 1], # subsample ratio of columns when constructing each tree\n",
        "    'colsample_bylevel': [0.66, 0.75, 1], # subsample ratio of columns when constructing each tree\n",
        "    'colsample_bynode':  [0.66, 0.75, 1], # subsample ratio of columns when constructing each tree\n",
        "    'eta':               [0.1, 0.2, 0.25, 0.33],  # boosting learning rate \n",
        "}"
      ],
      "metadata": {
        "id": "NQKEN-ppndNF"
      },
      "id": "NQKEN-ppndNF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = initial_params.copy()\n",
        "for param, values in grid_params.items():\n",
        "  best_score = 9e9\n",
        "  print('\\nbest_params:', best_params)\n",
        "  for value in values:\n",
        "    print('testing {}={}'.format(param, value))\n",
        "    xgb_params = best_params.copy()\n",
        "    xgb_params.update({param: value})\n",
        "    xgb_model = xgb.train(\n",
        "        params                = xgb_params,\n",
        "        dtrain                = D_train,\n",
        "        evals                 = [(D_test,'eval')],\n",
        "        num_boost_round       = 150,\n",
        "        early_stopping_rounds = 5,\n",
        "        verbose_eval          = 0,\n",
        "    )\n",
        "    if xgb_model.best_score < best_score:\n",
        "      best_score = xgb_model.best_score\n",
        "      best_params.update({param: value})\n",
        "      print('new best value found: {}={} ({})'.format(param, value, best_score))"
      ],
      "metadata": {
        "id": "qle3C5TdENax"
      },
      "id": "qle3C5TdENax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving results and using CV to measure the accuracy"
      ],
      "metadata": {
        "id": "vdbhN-5oR9mM"
      },
      "id": "vdbhN-5oR9mM"
    },
    {
      "cell_type": "code",
      "source": [
        "best_params.update({\n",
        "    'num_parallel_tree': 25,              # incresing number of trees\n",
        "    'num_class':         20,              # need this parameter if we want to use softmax\n",
        "    'objective':         'multi:softmax', # for multiclass classification (use simple rmse to make it go faster)\n",
        "})\n",
        "\n",
        "best_params"
      ],
      "metadata": {
        "id": "OHUDfbHTNeL5"
      },
      "id": "OHUDfbHTNeL5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/xgb_hyperparameters.json', mode='w') as file:\n",
        "  json.dump(best_params, file, indent=4)"
      ],
      "metadata": {
        "id": "_04IdznhM2HO"
      },
      "id": "_04IdznhM2HO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.train(\n",
        "    params                = best_params,\n",
        "    dtrain                = D_train,\n",
        "    evals                 = [(D_train,'train'), (D_test,'eval')],\n",
        "    num_boost_round       = 500,\n",
        "    early_stopping_rounds = 10\n",
        ")"
      ],
      "metadata": {
        "id": "wagznFy8nkfz"
      },
      "id": "wagznFy8nkfz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = xgb_model.predict(D_test, ntree_limit=xgb_model.best_ntree_limit).astype(np.int64)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "CFP-WnrtCBRX"
      },
      "id": "CFP-WnrtCBRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CV"
      ],
      "metadata": {
        "id": "EZVYg3OhSFPp"
      },
      "id": "EZVYg3OhSFPp"
    },
    {
      "cell_type": "code",
      "source": [
        "D_train = xgb.DMatrix(X, label=y_encoder)\n",
        "\n",
        "df_xgb_cv = xgb.cv(\n",
        "    params                = best_params,\n",
        "    dtrain                = D_train,\n",
        "    num_boost_round       = 50,\n",
        "    early_stopping_rounds = 5,\n",
        "    nfold                 = 5,\n",
        "    stratified            = True,\n",
        "    verbose_eval          = True,\n",
        "    shuffle               = True\n",
        ")"
      ],
      "metadata": {
        "id": "SXOpf_PDCBJw"
      },
      "id": "SXOpf_PDCBJw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1 - df_xgb_cv['test-merror-mean'].mean()"
      ],
      "metadata": {
        "id": "3A4E4jnkXs1K"
      },
      "id": "3A4E4jnkXs1K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions to the test set"
      ],
      "metadata": {
        "id": "_lFXtErTRmdf"
      },
      "id": "_lFXtErTRmdf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing datasets"
      ],
      "metadata": {
        "id": "APOnXfoMagg0"
      },
      "id": "APOnXfoMagg0"
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the datasets\n",
        "df_train = pd.read_csv('/content/task_1/train_set.csv')\n",
        "df_test  = pd.read_csv('/content/task_1/test_set.csv') \n",
        "\n",
        "# separating X and y\n",
        "X_train = df_train.drop('y', axis=1).to_numpy()\n",
        "y_train = df_train['y'].to_numpy()\n",
        "X_test  = df_test.to_numpy()\n",
        "\n",
        "# beeing sure its right\n",
        "assert X_train.shape == (31714, 100)\n",
        "assert X_test.shape == (800, 100)\n",
        "assert y_train.shape == (31714,)\n",
        "\n",
        "# fitting the scaler with the training data and using it to transform the test data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# encoding y\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoder = encoder.fit_transform(y_train)"
      ],
      "metadata": {
        "id": "n0kgnGcvRn64"
      },
      "id": "n0kgnGcvRn64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training XGB with the full training set"
      ],
      "metadata": {
        "id": "uf9yjaVzakrc"
      },
      "id": "uf9yjaVzakrc"
    },
    {
      "cell_type": "code",
      "source": [
        "# creating xbg data matrices\n",
        "D_train = xgb.DMatrix(X_train, label=y_train_encoder)\n",
        "D_test  = xgb.DMatrix(X_test)\n",
        "\n",
        "# getting the best parameters\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/xgb_hyperparameters.json', mode='r') as file:\n",
        "  best_params = json.load(file)\n",
        "print(best_params, '\\n')\n",
        "\n",
        "# # fitting xgb\n",
        "xgb_model = xgb.train(\n",
        "    params                = best_params,\n",
        "    dtrain                = D_train,\n",
        "    evals                 = [(D_train, 'train')],\n",
        "    num_boost_round       = 15,\n",
        "    early_stopping_rounds = 5,\n",
        "    verbose_eval          = True,\n",
        ")"
      ],
      "metadata": {
        "id": "UZS2OXjOSPEw"
      },
      "id": "UZS2OXjOSPEw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting test set"
      ],
      "metadata": {
        "id": "rofTaminazAE"
      },
      "id": "rofTaminazAE"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_encoder = xgb_model.predict(D_test).astype(np.int64)\n",
        "y_pred = encoder.inverse_transform(y_pred_encoder)\n",
        "np.savetxt(\n",
        "    fname   = '/content/drive/MyDrive/Colab Notebooks/xgb_predictions_test_set.csv',\n",
        "    fmt     = '%s',\n",
        "    newline = '\\n',\n",
        "    X       = y_pred\n",
        ")"
      ],
      "metadata": {
        "id": "_pc8H8_DZzWF"
      },
      "id": "_pc8H8_DZzWF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5fd7cc4f",
        "BBvRsrAZK9Ej",
        "c8faec9d",
        "7a7e1440",
        "e4952b2a",
        "ff3a8d56",
        "be1736bf"
      ],
      "name": "Cópia de Cópia de final_project_part_i.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}